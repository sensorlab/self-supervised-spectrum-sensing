{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0f5385d-73aa-4fd4-a4ee-db26eab5de58",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyclustertend in /opt/conda/lib/python3.10/site-packages (1.6.2)\n",
      "Requirement already satisfied: scikit-learn<0.25.0,>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from pyclustertend) (0.24.2)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.3.3 in /opt/conda/lib/python3.10/site-packages (from pyclustertend) (3.6.2)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from pyclustertend) (1.5.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.19.1 in /opt/conda/lib/python3.10/site-packages (from pyclustertend) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.3.3->pyclustertend) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.3.3->pyclustertend) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.3.3->pyclustertend) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.3.3->pyclustertend) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.3.3->pyclustertend) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.3.3->pyclustertend) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.3.3->pyclustertend) (1.0.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.3.3->pyclustertend) (4.38.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0.0,>=1.2.0->pyclustertend) (2022.6)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<0.25.0,>=0.24.0->pyclustertend) (1.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<0.25.0,>=0.24.0->pyclustertend) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<0.25.0,>=0.24.0->pyclustertend) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.3.3->pyclustertend) (1.16.0)\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.14.0)\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (3.6.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.13.0.post200)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable) (0.2.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (3.7.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.10/site-packages (from h5py) (1.23.5)\n",
      "Collecting lightning\n",
      "  Downloading lightning-2.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting croniter<1.4.0,>=1.3.0\n",
      "  Downloading croniter-1.3.8-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: packaging<25.0,>=17.1 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.11.1)\n",
      "Collecting lightning-utilities<2.0,>=0.7.0\n",
      "  Using cached lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: PyYAML<8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0)\n",
      "Requirement already satisfied: urllib3<3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.13)\n",
      "Requirement already satisfied: psutil<7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (5.9.4)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.65.0)\n",
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-2.0.1-py3-none-any.whl (716 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m716.4/716.4 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.28.1)\n",
      "Requirement already satisfied: Jinja2<5.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (3.1.2)\n",
      "Requirement already satisfied: websocket-client<3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.4.2)\n",
      "Collecting pydantic<3.0\n",
      "  Downloading pydantic-1.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fastapi<0.89.0\n",
      "  Downloading fastapi-0.88.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<6.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.4.0)\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (5.6.0)\n",
      "Collecting deepdiff<8.0,>=5.7.0\n",
      "  Downloading deepdiff-6.3.0-py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch<4.0,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.13.0.post200)\n",
      "Collecting lightning-cloud>=0.5.31\n",
      "  Downloading lightning_cloud-0.5.32-py3-none-any.whl (545 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m546.0/546.0 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting starsessions<2.0,>=1.2.1\n",
      "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting websockets<12.0\n",
      "  Downloading websockets-11.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchmetrics<2.0,>=0.7.0\n",
      "  Using cached torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
      "Collecting arrow<3.0,>=1.2.0\n",
      "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2022.11.0)\n",
      "Collecting dateutils<2.0\n",
      "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
      "Collecting inquirer<5.0,>=2.10.0\n",
      "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
      "Collecting starlette<2.0\n",
      "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rich<15.0,>=12.3.0\n",
      "  Downloading rich-13.3.3-py3-none-any.whl (238 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.7/238.7 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.23.5)\n",
      "Collecting uvicorn<2.0\n",
      "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click<10.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (8.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.3.2.post1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from dateutils<2.0->lightning) (2022.6)\n",
      "Collecting ordered-set<4.2.0,>=4.0.2\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Collecting starlette<2.0\n",
      "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette<2.0->lightning) (3.6.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Using cached aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "Collecting blessed>=1.19.0\n",
      "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting readchar>=3.0.6\n",
      "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
      "Collecting python-editor>=1.0.4\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<5.0->lightning) (2.1.1)\n",
      "Collecting fastapi[all]\n",
      "  Downloading fastapi-0.95.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from lightning-cloud>=0.5.31->lightning) (1.16.0)\n",
      "Requirement already satisfied: pyjwt in /opt/conda/lib/python3.10/site-packages (from lightning-cloud>=0.5.31->lightning) (2.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=17.1->lightning) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (2.1.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.13.0)\n",
      "Collecting markdown-it-py<3.0.0,>=2.2.0\n",
      "  Using cached markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "Collecting itsdangerous<3.0.0,>=2.0.1\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting h11>=0.8\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (22.1.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.5)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: setuptools>=41.0 in /opt/conda/lib/python3.10/site-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (65.5.1)\n",
      "Collecting fastapi[all]\n",
      "  Downloading fastapi-0.94.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.94.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.93.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.92.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.91.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.90.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.90.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.89.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.89.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson>=3.2.1\n",
      "  Downloading orjson-3.8.9-cp310-cp310-manylinux_2_28_x86_64.whl (144 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.1/144.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpx>=0.23.0\n",
      "  Using cached httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1\n",
      "  Downloading ujson-5.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting email-validator>=1.1.1\n",
      "  Downloading email_validator-1.3.1-py2.py3-none-any.whl (22 kB)\n",
      "Collecting python-multipart>=0.0.5\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dnspython>=1.15.0\n",
      "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpcore<0.17.0,>=0.15.0\n",
      "  Using cached httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3\n",
      "  Using cached rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting httptools>=0.5.0\n",
      "  Downloading httptools-0.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (414 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.1/414.1 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13\n",
      "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rfc3986, python-editor, websockets, uvloop, ujson, readchar, python-multipart, python-dotenv, pydantic, orjson, ordered-set, multidict, mdurl, itsdangerous, httptools, h11, frozenlist, dnspython, blessed, async-timeout, yarl, watchfiles, uvicorn, torchmetrics, starlette, markdown-it-py, lightning-utilities, inquirer, httpcore, email-validator, deepdiff, dateutils, croniter, arrow, aiosignal, starsessions, rich, httpx, fastapi, aiohttp, pytorch-lightning, lightning-cloud, lightning\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 arrow-1.2.3 async-timeout-4.0.2 blessed-1.20.0 croniter-1.3.8 dateutils-0.6.12 deepdiff-6.3.0 dnspython-2.3.0 email-validator-1.3.1 fastapi-0.88.0 frozenlist-1.3.3 h11-0.14.0 httpcore-0.16.3 httptools-0.5.0 httpx-0.23.3 inquirer-3.1.3 itsdangerous-2.1.2 lightning-2.0.1 lightning-cloud-0.5.32 lightning-utilities-0.8.0 markdown-it-py-2.2.0 mdurl-0.1.2 multidict-6.0.4 ordered-set-4.1.0 orjson-3.8.9 pydantic-1.10.7 python-dotenv-1.0.0 python-editor-1.0.4 python-multipart-0.0.6 pytorch-lightning-2.0.1 readchar-4.0.5 rfc3986-1.5.0 rich-13.3.3 starlette-0.22.0 starsessions-1.3.0 torchmetrics-0.11.4 ujson-5.7.0 uvicorn-0.21.1 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.1 yarl-1.8.2\n"
     ]
    }
   ],
   "source": [
    "# Installs\n",
    "!pip install pyclustertend\n",
    "!conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch -y\n",
    "!pip install torchvision prettytable\n",
    "!pip install h5py tqdm\n",
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca4f9ac-7b2f-41d2-ad18-aae983a50bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# Imports cell\n",
    "import sys\n",
    "import math, random, numpy as np\n",
    "import json\n",
    "import datetime\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models, transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from tqdm import tqdm\n",
    "from data import SignalDatasetV2\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import ConcatDataset\n",
    "from prettytable import PrettyTable\n",
    "from scipy.sparse import data\n",
    "import pickle\n",
    "\n",
    "import SSLUtils as utls\n",
    "from SSLConstants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e13186e-ddac-43f3-a07a-91705e813784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device:  0\n",
      "Current device:  True\n"
     ]
    }
   ],
   "source": [
    "# Setup GPU\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)\n",
    "    device = torch.device('cuda')\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    pin_memory = True\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    pin_memory = False\n",
    "\n",
    "print(\"Current device: \", torch.cuda.current_device())  \n",
    "print(\"Current device: \", torch.cuda.is_available())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab7bfabd-8cca-400b-a5fc-d6986afa3cfc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Cluster: \n",
      "24\n",
      "\n",
      " PCA number: \n",
      "20\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting features: 100%|██████████| 313/313 [00:05<00:00, 52.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch:\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting features: 100%|██████████| 313/313 [00:06<00:00, 51.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  45%|████▍     | 140/313 [00:07<00:09, 19.02batch/s, loss=0.752, lr=0.001]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 102\u001b[0m\n\u001b[1;32m     93\u001b[0m labeled_dataset \u001b[38;5;241m=\u001b[39m SignalDatasetV2(\n\u001b[1;32m     94\u001b[0m     window\u001b[38;5;241m=\u001b[39mIMG_SIZE, stride\u001b[38;5;241m=\u001b[39mIMG_STRIDE, labels\u001b[38;5;241m=\u001b[39mpseudo_labels[\u001b[38;5;241m0\u001b[39m], \n\u001b[1;32m     95\u001b[0m     limit\u001b[38;5;241m=\u001b[39mLIMIT_IMAGES, dataset_path\u001b[38;5;241m=\u001b[39mDATASET_PATH, three_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     96\u001b[0m )\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Commands for usage of the MNIST dataset\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# nn_input.targets = pseudo_labels\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# train for one epoch\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mutls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabeled_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m all_stats\u001b[38;5;241m.\u001b[39mappend(stats)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Save the current model state.\u001b[39;00m\n",
      "File \u001b[0;32m~/working folder/code/SSLUtils.py:243\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, train_dataset, device, pin_memory)\u001b[0m\n\u001b[1;32m    235\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# scaler.step(optimizer)\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# Updates the scale for next iteration\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# scaler.update()\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# Summary info (current loss)\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m running_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# Calculate running loss\u001b[39;00m\n\u001b[1;32m    246\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(running_loss) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(running_loss)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main cell\n",
    "\n",
    "pca_dimensions = list(range(20, 21))\n",
    "num_clusters = list(range(24, 25, 1))\n",
    "nmi_list = []\n",
    "\n",
    "raw_dataset = SignalDatasetV2(window=IMG_SIZE, stride=IMG_STRIDE,\n",
    "                              limit=LIMIT_IMAGES, dataset_path=DATASET_PATH, three_channels=False)\n",
    "num_learning_iter = 5\n",
    "\n",
    "nn_input = raw_dataset\n",
    "\n",
    "for n in num_clusters:\n",
    "    for p in pca_dimensions:\n",
    "\n",
    "\n",
    "        d_t_string = datetime.datetime.now().strftime(\"%H_%M_%S_%d_%m_%Y\")\n",
    "\n",
    "        CURRENT_MODEL_PATH = '../results/models/' + str(num_learning_iter) + 'e_kmeans_c' + str(n).zfill(2)\\\n",
    "        + 'pca' + str(p).zfill(2) + 'e' + str(MAX_EPOCHS) + 'RN18_' + d_t_string + '.pt'\n",
    "\n",
    "        CURRENT_STAT_PATH = '../results/stats/' + str(num_learning_iter) + 'e_kmeans_c' + str(n).zfill(2)\\\n",
    "        + 'pca' + str(p).zfill(2) + 'e' + str(MAX_EPOCHS) + 'RN18_' + d_t_string + '_stats.json'\n",
    "\n",
    "        KMEANS_MODEL_PATH = '../results/models/' + str(num_learning_iter) + 'e_kmeans_c' + str(n).zfill(2)\\\n",
    "        + 'pca' + str(p).zfill(2) + 'e' + str(MAX_EPOCHS) + 'RN18_' + d_t_string + '.pkl'\n",
    "\n",
    "        print(\"\\n Cluster: \")\n",
    "        print(n)\n",
    "        print(\"\\n PCA number: \")\n",
    "        print(p)\n",
    "\n",
    "        utls.set_all_seed(42)\n",
    "\n",
    "        if not USE_VGG:            \n",
    "            # Using ResNet18\n",
    "            model = models.resnet18()\n",
    "            model.fc = nn.Linear(512, n)\n",
    "            # Adapt last, fully connected layer, if one channel images are used\n",
    "            model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        else:\n",
    "            # Using VGG11\n",
    "            model = models.vgg11()\n",
    "            model.classifier[3] = nn.Linear(4096, 512)\n",
    "            model.classifier[6] = nn.Linear(512, n)\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        # Optimizer for NN\n",
    "        #optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "        if LOAD_SAVED_MODEL:\n",
    "            checkpoint = torch.load(SAVED_MODEL_PATH)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            LOADED_EPOCH = checkpoint['epoch'] + 1 # Add 1 because of 0-indexing\n",
    "            loss = checkpoint['loss']\n",
    "            print(\"saved model loaded\")\n",
    "    \n",
    "        print(next(model.parameters()).device)\n",
    "    \n",
    "        # Principal Component Analysis\n",
    "        pca = IncrementalPCA(n_components=p, batch_size=256, whiten=True)\n",
    "\n",
    "        # mini-batch K-Means\n",
    "        kmeans = MiniBatchKMeans(n_clusters=n, batch_size=256, \n",
    "                                init_size=3*n)\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        all_stats = []\n",
    "        # Check if existing model is used in order to load the stat data.\n",
    "        if LOAD_SAVED_MODEL:\n",
    "            with open(SAVED_STAT_PATH, 'r') as f:\n",
    "                all_stats = json.load(f)\n",
    "        \n",
    "        # Get initial labels\n",
    "        pseudo_labels = utls.cluster(pca, kmeans, model, nn_input, device, pin_memory)\n",
    "\n",
    "        for _ in range(MAX_EPOCHS-LOADED_EPOCH+num_learning_iter):\n",
    "      \n",
    "            print(\"\\n Epoch:\")\n",
    "            print(LOADED_EPOCH + _)\n",
    "      \n",
    "            if _ % num_learning_iter == 0:\n",
    "                # generate labels\n",
    "                pseudo_labels = utls.cluster(pca, kmeans, model, nn_input, device, pin_memory)\n",
    "\n",
    "            # make new dataset with labels matched to images (Spectrum data)\n",
    "            labeled_dataset = SignalDatasetV2(\n",
    "                window=IMG_SIZE, stride=IMG_STRIDE, labels=pseudo_labels[0], \n",
    "                limit=LIMIT_IMAGES, dataset_path=DATASET_PATH, three_channels=False\n",
    "            )\n",
    "    \n",
    "            # Commands for usage of the MNIST dataset\n",
    "            # nn_input.targets = pseudo_labels\n",
    "      \n",
    "            # train for one epoch\n",
    "            stats = utls.train_epoch(model, optimizer, labeled_dataset, device, pin_memory)\n",
    "            all_stats.append(stats)\n",
    "\n",
    "            # Save the current model state.\n",
    "            torch.save({\n",
    "                    'epoch': _ + LOADED_EPOCH,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': stats['running_loss'],\n",
    "                    }, CURRENT_MODEL_PATH)\n",
    "\n",
    "            # Save the stat data in .json file.\n",
    "            with open(CURRENT_STAT_PATH, 'w') as f:\n",
    "                json.dump(all_stats, f, indent=2) \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b4fd34-3c2f-457d-abd3-30cbb4f012ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
